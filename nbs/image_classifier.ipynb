{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1c26823-c58d-4268-b247-9cfed2467b39",
   "metadata": {},
   "source": [
    "# Building a Neural Network for Image Classification: A Step-by-Step Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dca4c6",
   "metadata": {},
   "source": [
    "Image classification is one of the fundamental deep learning tasks. While modern frameworks like PyTorch, JAX, Keras, and TensorFlow offer a convenient abstraction to build and train neural networks, crafting one from scratch provides a more comprehensive understanding of the nuances involved.\n",
    "\n",
    "In this notebook, we will implement in Python the essential modules required to build and train a multilayer perceptron that classifies garment images. In particular, we will delve into the fundamentals of approximation, non-linearity, regularization, optimizers, gradients, and backpropagation. Additionally, we explore the significance of random parameter initialization and the benefits of training in mini-batches.\n",
    "\n",
    "By the end, you will be able to construct the fundamental building blocks of a neural network from scratch, understand how it learns, and deploy it to HuggingFace to classify real-world garment images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb79d7a1",
   "metadata": {},
   "source": [
    "### The Intuition behind our Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44479568",
   "metadata": {},
   "source": [
    "Our goal is to classify garment images by approximating a large mathematical function based on a training dataset of such images. We will begin this process by randomly initializing the parameters of our mathematical function, and adjusting them to combine input pixel values, until we obtain favorable outputs (in form of class predictions). This iterative method seeks to identify features in the training dataset that differentiate between classes, facilitating more accurate predictions.\n",
    "\n",
    "The foundation for this approach is the [Universal Approximation Theorem](https://en.wikipedia.org/wiki/Universal_approximation_theorem), which highlights the significance of combining linear operations and non-linear functions to approximate complex patterns, such as those needed for computer vision.\n",
    "\n",
    "The principle of teaching computers through examples, rather than explicit programming, dates back to [Arthur Samuel](https://ieeexplore.ieee.org/document/5392560) in 1949. Samuel further suggested the concept of using weights as function parameters that can be adjusted to influence the program's behavior and outputs. And underscored the need for an automatic method to test and optimize these weights based on their performance in real tasks.\n",
    " \n",
    "We will implement this approximation method and approximate the weights automatically, applying [Stochastic Gradient Descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) in mini-batches, which in practice involves the following steps:\n",
    "\n",
    "1. Initialize parameters (the weights and biases of our model).\n",
    "2. Calculate predictions on a mini-batch.\n",
    "3. Calculate the average loss between the predictions and the targets.\n",
    "4. Calculate the gradients, which provide an indication of how the parameters need to change to minimize the loss.\n",
    "5. Update the weights based on the gradients and a learning rate.\n",
    "6. Repeat from step 2.\n",
    "7. Stop the process once a condition is met, such as a time constraint or when the training/validation losses and metrics cease to improve.\n",
    "\n",
    "*A mini-batch refers to a randomly selected subset of the training dataset that is used to calculate the loss and update the weights in each iteration*.\n",
    "\n",
    "*Gradients are a measure inferred from the derivative of a function that indicates how the output of the function would change by modifying its parameters. Within the context of neural networks, they indicate the direction and magnitude in which we need to change each weight to improve our model*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00475e2",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d7b71c-b316-4499-a2a5-60c2c2b2f8b2",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60157f1e",
   "metadata": {},
   "source": [
    "In the following sections, we dive into the implementation details of the required components to build and train a multilayer perceptron that classifies garment images. For simpler integration with advanced functionality like computing gradients, these components will be defined as custom PyTorch modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fea1e3",
   "metadata": {},
   "source": [
    "#### Linear Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e425942",
   "metadata": {},
   "source": [
    "At the heart of our neural network are linear functions. These linear functions perform two key operations: (i) transformation of input values by their weights and biases through matrix multiplication, and (ii) dimensionality reduction (or augmentation in some cases).\n",
    "\n",
    "This transformation projects input values into a different space, which along the use of stacked linear layers, enables the network to progressively learn more abstract and complex patterns.\n",
    "\n",
    "Dimensionality reduction is achieved when the number of output units in a linear layer is smaller than the number of inputs. This compression forces the layer to capture the most salient features of the higher-dimensional input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1413e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('GPU State:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, std: float = 0.1):\n",
    "        \"\"\"\n",
    "        Initializes linear layer with random weights. \n",
    "        Weights and biases are registered as parameters, allowing for \n",
    "        gradient computation and update during backpropagation.\n",
    "        \"\"\"\n",
    "        super(Linear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        weight = torch.randn(in_features, out_features, requires_grad=True) * std\n",
    "        bias = torch.zeros(out_features, requires_grad=True)\n",
    "        \n",
    "        self.weight = nn.Parameter(weight)\n",
    "        self.bias = nn.Parameter(bias)\n",
    "        self.to(device=device)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Perform linear transformation by multiplying the input tensor\n",
    "        with the weight matrix, and adding the bias.\n",
    "        \"\"\"\n",
    "        return x @ self.weight + self.bias\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"\n",
    "        String representation of the linear layer.\n",
    "\n",
    "        Returns:\n",
    "            str: A string containing the number of input and output features, and whether the layer has a bias.\n",
    "        \"\"\"\n",
    "        return f'in_features={self.in_features}, out_features={self.out_features}, bias={self.bias is not None}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dedf50c",
   "metadata": {},
   "source": [
    "It is important to note that the weights are randomly initialized to break symmetry and enable effective learning. If all parameters were initialized to the same value, such as zeros, they will compute the same gradients during backpropagation, leading to identical weight updates and slower (or non)convergence. This symmetry would prevent the network from learning patterns in the data.\n",
    "\n",
    "Furthermore,  scaling weights is a common practice in initialization. This helps in controlling the variance, and can have a big impact on the training dynamics. Note that a large scaling value can lead to gradients becoming excessively large during backpropagation, resulting in the exploding gradients problem wherein weights would increase exponentially and overflow to NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98b4348",
   "metadata": {},
   "source": [
    "#### Introducing non-linearity\n",
    "\n",
    "Without non-linearity, no matter how many layers our neural network has, it would still behave like a single-layer perceptron. This is due to the fact that the sum of multiple linear functions is  itself another linear function, which would prevent the model from approximating complex patterns.\n",
    "\n",
    "To overcome this limitation, we adhere to the Universal Approximation Theorem and introduce non-linearity by implementing the rectified linear unit (ReLU), a widely used and simple activation function that sets negative values to zero while preserving positive values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b062bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(nn.Module):\n",
    "    \"\"\"\n",
    "    Rectified Linear Unit (ReLU) activation function.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(x: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.clip(x, 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a8960a",
   "metadata": {},
   "source": [
    "#### Regularization\n",
    "\n",
    "Regularization is a fundamental technique used to prevent overfitting in neural networks, ensuring that models generalize well to unseen data. One effective method of regularization is the implementation of the dropout function. Dropout works by randomly deactivating a subset of neurons in the network during training, which prevents the model from becoming overly reliant on any single neuron or feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c37bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(nn.Module):\n",
    "    \"\"\"\n",
    "    Applies the dropout regularization technique to the input tensor.\n",
    "    During training, randomly sets a fraction of input units to 0 with probability `p`,\n",
    "    scaling the remaining values by `1 / (1 - p)` to maintain the same expected output sum.\n",
    "    During evaluation, no dropout is applied.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.2):\n",
    "        super(Dropout, self).__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.training:\n",
    "            mask = (torch.rand(x.shape) > self.p).float().to(x) / (1 - self.p)\n",
    "            return x * mask\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23293c60",
   "metadata": {},
   "source": [
    "#### Transformation Layer\n",
    "\n",
    "Since we are working with the Fashion MNIST dataset, where images need to be flattened, we include a view transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52e5e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    \"\"\"\n",
    "    Reshape the input tensor by flattening all dimensions except the first dimension.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x.view(x.size(0), -1) reshapes the x tensor to (x.size(0), N)\n",
    "        where N is the product of the remaining dimensions.\n",
    "        E.g. (batch_size, 28, 28) -> (batch_size, 784)\n",
    "        \"\"\"\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b50822",
   "metadata": {},
   "source": [
    "#### Sequential Layer\n",
    "\n",
    "To construct the full neural network architecture, we need a way to connect the individual linear operations and activation functions in a sequential manner, forming a feedforward path from the inputs to the outputs. This is achieved by using a sequential layer, which allows to define the specific order and composition of the various layers in our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential(nn.Module):\n",
    "    \"\"\"\n",
    "    Sequential container for stacking multiple modules,\n",
    "    passing the output of one module as input to the next.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *layers):\n",
    "        super(Sequential, self).__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"\n",
    "        String representation of the Sequential module.\n",
    "\n",
    "        Returns:\n",
    "            str: A string containing the layers in the Sequential container.\n",
    "        \"\"\"\n",
    "        layer_str = '\\n'.join([f' ({i}): {layer}' for i, layer in enumerate(self.layers)])\n",
    "        return f'{self.__class__.__name__}(\\n{layer_str}\\n)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68deba7",
   "metadata": {},
   "source": [
    "#### Classifier Model\n",
    "\n",
    "After flattening the input images, we stack linear operations with non-linear functions, enabling the network to learn hierarchical representations and approximate complex patterns in the data. This is essential for tasks like image classification, where the network needs to capture visual features to distinguish between various classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5effc483",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Classifier model consisting of a sequence of linear layers and ReLU activations,\n",
    "    followed by a final linear layer that outputs logits (unnormalized scores)\n",
    "    for each of the 10 garment classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        The output logits of the last layer can be passed directly to\n",
    "        a loss function like CrossEntropyLoss, which will apply the \n",
    "        softmax function internally to calculate a probability distribution.\n",
    "        \"\"\"\n",
    "        super(Classifier, self).__init__()\n",
    "        self.labels = ['T-shirt/Top', 'Trouser/Jeans', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle-Boot']\n",
    "        \n",
    "        self.main = Sequential(\n",
    "            Flatten(),\n",
    "            Linear(in_features=784, out_features=256),\n",
    "            ReLU(),\n",
    "            Dropout(0.2),\n",
    "            Linear(in_features=256, out_features=64),\n",
    "            ReLU(),\n",
    "            Dropout(0.2),\n",
    "            Linear(in_features=64, out_features=10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.main(x)\n",
    "    \n",
    "    def predictions(self, x):\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(x)\n",
    "            probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "            predictions = dict(zip(self.labels, probs.cpu().detach().numpy().flatten()))    \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94711ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b4e7dd",
   "metadata": {},
   "source": [
    "Verify that the parameters have been properly registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981ccdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.parameters())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b06a472",
   "metadata": {},
   "source": [
    "#### Backpropagation\n",
    "\n",
    "We implement a basic optimizer to automatically adjust the neural network's parameters, weights and biases,  based on gradients. Computed during backpropagation, gradients indicate how to update these parameters to minimize the loss function. Using these gradients, the optimizer updates the parameters in a stepwise manner, with the step size determined by the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3442b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    \"\"\"\n",
    "    Update model parameters during training.\n",
    "    \n",
    "    It performs a simple gradient descent step by updating the parameters\n",
    "    based on their gradients and the specified learning rate (lr).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        for p in self.params:\n",
    "            p.data -= p.grad.data * self.lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"\"\"\n",
    "        Reset the gradients of all parameters to zero.\n",
    "        Since PyTorch accumulates gradients, this method ensures that\n",
    "        the gradients from previous optimization steps do not interfere\n",
    "        with the current step.\n",
    "        \"\"\"\n",
    "        for p in self.params:\n",
    "            p.grad = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a9175d",
   "metadata": {},
   "source": [
    "*In 1974, Paul Werbos introduced the concept of backpropagation for neural networks. This development was almost entirely ignored for decades, but today it is considered one of the most important AI foundations.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37a45f7",
   "metadata": {},
   "source": [
    "#### Init Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e27a86b",
   "metadata": {},
   "source": [
    "Feel free to experiment with different learning rates and batch sizes (32, 64, 128). Keep in mind that if the batch size is too large, it might exceed the GPU's memory capacity, causing an out-of-memory error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7469d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LearnerConfig:\n",
    "    \"\"\"\n",
    "    Configuration class for the Learner.\n",
    "\n",
    "    This class holds the hyperparameters and settings for training the model.\n",
    "    \"\"\"\n",
    "\n",
    "    model: nn.Module\n",
    "    criterion: nn.Module\n",
    "    epochs: int\n",
    "    batch_size: int\n",
    "    lr: float\n",
    "    device: str\n",
    "\n",
    "    # Example configuration\n",
    "    config = LearnerConfig(\n",
    "        model=model,\n",
    "        criterion=nn.CrossEntropyLoss(),\n",
    "        epochs=25,\n",
    "        batch_size=32,\n",
    "        lr=0.005,\n",
    "        device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4283932c",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e2c140",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96379b73",
   "metadata": {},
   "source": [
    "#### Data Loaders\n",
    "\n",
    "In the training process, we need to efficiently handle the loading and preprocessing of the dataset. For this purpose, we will use torch.utils.data.DataLoader, a utility class provided by PyTorch that helps with batching, shuffling, and loading data in parallel.\n",
    "\n",
    "Using mini-batches instead of the entire dataset results in (i) computational efficiency as GPUs tend to perform better when they have a larger amount of work to process in parallel, (ii) better generalization by randomly shuffling the mini-batches on every epoch, which introduces variance and prevents the model from overfitting, and (iii) reduced memory usage as it is a practical choice to not overload the GPU's memory with the entire dataset at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08fa0ad4-797d-4981-8d90-22640823de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data = datasets.FashionMNIST(root = 'data', train = True, transform = ToTensor(), download = True)\n",
    "test_data = datasets.FashionMNIST(root = 'data', train = False, transform = ToTensor())\n",
    "num_workers = 1\n",
    "\n",
    "loaders = {'train' : DataLoader(train_data, batch_size=config.batch_size, shuffle=True, num_workers=num_workers),\n",
    "           'test'  : DataLoader(test_data, batch_size=config.batch_size, shuffle=False, num_workers=num_workers)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aff5113",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.data.size(), test_data.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacbf6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "label_names = ['T-shirt/Top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 5, 5\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(img.squeeze())\n",
    "    plt.xlabel(label_names[label])\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fbfba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea37b5c",
   "metadata": {},
   "source": [
    "#### Fitting the Model\n",
    "\n",
    "With the neural network architecture and data loaders in place, we can now focus on the process of training the model, also known as fitting the model to the data. This involves implementing a training loop that iterates over the dataset, computes the predictions and loss, and updates the model's parameters using backpropagation and an optimization algorithm.\n",
    "\n",
    "The training process can be divided into two main components: the training loop and the validation loop. The training loop is responsible for feeding the mini-batches of data to the model, computing the loss, and updating the model's parameters using backpropagation and the optimizer. This loop is typically run for a fixed number of epochs or until a certain stopping criterion is met.\n",
    "\n",
    "On the other hand, the validation loop is used to evaluate the model's performance on a separate validation dataset, which is not used for training. This helps monitor the model's generalization performance and prevents overfitting to the training data.\n",
    "\n",
    "In the following code, we implement a Learner class that encapsulates this logic and provides a convenient interface for fitting the model to the data and monitoring its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d9b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "    \"\"\"\n",
    "    Learner class for training and evaluating a model.\n",
    "\n",
    "    This class encapsulates the training and validation loops, as well as\n",
    "    utility methods for prediction, exporting the model, and calculating\n",
    "    accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, loaders):\n",
    "        \"\"\"\n",
    "        Initialize the Learner.\n",
    "\n",
    "        Args:\n",
    "            config (LearnerConfig): Configuration for the Learner.\n",
    "            loaders (dict): Dictionary of data loaders for training and testing.\n",
    "        \"\"\"\n",
    "        self.model = config.model\n",
    "        self.loaders = loaders\n",
    "        self.optimizer = Optimizer(self.model.parameters(), config.lr)\n",
    "        self.criterion = config.criterion\n",
    "        self.epochs = config.epochs\n",
    "        self.device = config.device\n",
    "        self.labels = ['T-shirt/Top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle-Boot']\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"\n",
    "        Train the model for one epoch.\n",
    "        \"\"\"\n",
    "        epoch_loss = 0.0\n",
    "        for x, y in self.loaders[\"train\"]:\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            batch_size = x.size(0)\n",
    "\n",
    "            # Zero out the gradients - otherwise, they will accumulate.\n",
    "            self.optimizer.zero_grad()\n",
    "   \n",
    "            # Forward pass, loss calculation, and backpropagation\n",
    "            output = self.model(x)\n",
    "            loss = self.criterion(output, y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item() * batch_size\n",
    "\n",
    "        train_loss = epoch_loss / len(self.loaders['train'].dataset)\n",
    "        return train_loss\n",
    "    \n",
    "    def valid_loss(self):\n",
    "        \"\"\"\n",
    "        Calculate the validation loss.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in self.loaders[\"test\"]:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                output = self.model(x)\n",
    "                val_loss += self.criterion(output, y).item() * y.size(0)\n",
    "        val_loss /= len(self.loaders[\"test\"].dataset)\n",
    "        return val_loss\n",
    "\n",
    "    def batch_accuracy(self, x, y):\n",
    "        \"\"\"\n",
    "        Calculate the accuracy for a batch of inputs (x) and targets (y).\n",
    "        \"\"\"        \n",
    "        _, preds = torch.max(x.data, 1)\n",
    "        return (preds == y).sum().item() / x.size(0)\n",
    "\n",
    "    def validate_epoch(self):\n",
    "        \"\"\"\n",
    "        Evaluate the model on the test dataset after an epoch.\n",
    "        \"\"\"        \n",
    "        accs = [self.batch_accuracy(self.model(x.to(self.device)), y.to(self.device))\n",
    "                for x, y in self.loaders[\"test\"]]\n",
    "        return sum(accs) / len(accs)\n",
    "            \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Train the model for the specified number of epochs.\n",
    "        \"\"\"\n",
    "        print('epoch\\ttrain_loss\\tval_loss\\ttest_accuracy')\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss = self.train_epoch(epoch)\n",
    "            valid_loss = self.valid_loss()\n",
    "            batch_accuracy = self.validate_epoch()\n",
    "            print(f'{epoch+1}\\t{train_loss:.6f}\\t{valid_loss:.6f}\\t{batch_accuracy:.6f}')\n",
    "\n",
    "        metrics = self.evaluate()\n",
    "        return metrics\n",
    "            \n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(x.to(self.device))\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "        return preds\n",
    "    \n",
    "    def export(self, path):\n",
    "        torch.save(self.model, path)\n",
    "                \n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in self.loaders[\"test\"]:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                outputs = self.model(x)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_targets.extend(y.cpu().numpy())\n",
    "\n",
    "        class_precision = precision_score(all_targets, all_preds, average=None)\n",
    "        class_recall = recall_score(all_targets, all_preds, average=None)\n",
    "        class_f1 = f1_score(all_targets, all_preds, average=None)\n",
    "\n",
    "        metrics = {label: {\"precision\": prec, \"recall\": rec, \"f1\": f1}\n",
    "                   for label, prec, rec, f1 in zip(self.labels, class_precision, class_recall, class_f1)}\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1bb93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(config, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e082bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7461542",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['T-shirt/Top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle-Boot']\n",
    "\n",
    "# Determine the maximum label length for padding\n",
    "max_label_len = max(len(label) for label in labels)\n",
    "\n",
    "# Print header row\n",
    "header = \"Label\".ljust(max_label_len + 2) + \"Precision\".ljust(12) + \"Recall\".ljust(12) + \"F1-score\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "# Print metrics for each class in a row\n",
    "for label, metric in zip(labels, metrics.values()):\n",
    "    row = label.ljust(max_label_len + 2) + \\\n",
    "        f\"{metric['precision']:.6f}\".ljust(12) + \\\n",
    "        f\"{metric['recall']:.6f}\".ljust(12) + \\\n",
    "        f\"{metric['f1']:.6f}\"\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be3963f",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ff49f1",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a53d94",
   "metadata": {},
   "source": [
    "After training the model, we can use it for inference, which involves making predictions on new, unseen data. The inference process is relatively straightforward: we pass the input data (e.g., new garment images) through the trained neural network, and it will output the predicted class probabilities or labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964be63c",
   "metadata": {},
   "source": [
    "#### From Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b980fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "images, _ = next(iter(loaders['test']))\n",
    "i = torch.randint(len(images), size=(1,)).item()\n",
    "img = images[i]\n",
    "\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(img.squeeze())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b49539",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = learner.model.predictions(img.to(device))\n",
    "dict(sorted(predictions.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa616541",
   "metadata": {},
   "source": [
    "#### From Exported Model using a real Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9324e5",
   "metadata": {},
   "source": [
    "learner.export('fashion_mnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252b894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((28, 28)),\n",
    "        transforms.Grayscale(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),  # Normalize\n",
    "        transforms.Lambda(lambda x: 1.0 - x),  # Invert colors\n",
    "        transforms.Lambda(lambda x: x[0]),\n",
    "        transforms.Lambda(lambda x: x.unsqueeze(0)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26501f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('fashion/dress.png')\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163de7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = transform(img)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(img.squeeze())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99988723",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('fashion_mnist_2311.pt')\n",
    "predictions = model.predictions(img.to(device))\n",
    "dict(sorted(predictions.items(), key=lambda item: item[1], reverse=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
